{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/Jinbao2333/AIFundamentals2024/blob/main/Project_2/Classify.ipynb","timestamp":1719330739063}],"gpuType":"T4","mount_file_id":"https://github.com/Jinbao2333/AIFundamentals2024/blob/main/Project_2/Classify.ipynb","authorship_tag":"ABX9TyMyxTByqInETlRsAHxJ+nAO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install accelerate -U\n","!pip install transformers[torch]\n"],"metadata":{"id":"d69Rgj_j1JfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from datasets import Dataset\n","\n","# 加载数据\n","data_path = '/content/drive/MyDrive/data/'\n","train_df = pd.read_csv(data_path + 'train.csv')\n","test_df = pd.read_csv(data_path + 'test.csv')\n","\n","# 只保留 'reviewbody' 和 'star' 列，并重命名 'reviewbody' 列为 'review'\n","train_df = train_df[['review', 'star']]\n","train_df = train_df.head(12000)\n","test_df = test_df[['review', 'star']]\n","test_df = test_df.head(1000)\n","\n","# 数据预处理函数\n","def preprocess_data(df):\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","    def tokenize_function(examples):\n","        return tokenizer(examples['review'], truncation=True, padding=True)\n","\n","    dataset = Dataset.from_pandas(df)\n","    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","    return tokenized_dataset\n","\n","# 预处理训练集和测试集\n","train_dataset = preprocess_data(train_df)\n","test_dataset = preprocess_data(test_df)\n","\n","# 添加标签\n","def add_labels(example):\n","    example['labels'] = example['star']\n","    return example\n","\n","train_dataset = train_dataset.map(add_labels)\n","test_dataset = test_dataset.map(add_labels)\n","\n","# 加载预训练的BERT模型\n","model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=1)  # num_labels=1 表示回归任务\n","\n","# 定义训练参数\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_dir='./logs',  # 用于存储日志\n","    logging_steps=10,\n",")\n","\n","# 创建Trainer实例\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")\n","\n","# 开始训练\n","trainer.train()\n","\n","# 评估模型\n","results = trainer.evaluate()\n","print(results)\n"],"metadata":{"id":"6wtfEV4h1Lo3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow tensorboard\n"],"metadata":{"id":"uKv7Sx7CBnAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n","import matplotlib.pyplot as plt\n","\n","# 定义函数来加载和提取损失数据\n","def load_and_extract_losses(log_file):\n","    event_acc = EventAccumulator(log_file)\n","    event_acc.Reload()\n","\n","    tags = event_acc.Tags()['scalars']\n","    print(f\"All tags for {log_file}: {tags}\")\n","\n","    train_losses = []\n","    eval_losses = []\n","\n","    if 'train/loss' in tags:\n","        train_events = event_acc.Scalars('train/loss')\n","        train_losses = [event.value for event in train_events]\n","    else:\n","        print(f\"No 'train/loss' tag found in {log_file}.\")\n","\n","    if 'eval/loss' in tags:\n","        eval_events = event_acc.Scalars('eval/loss')\n","        eval_losses = [event.value for event in eval_events]\n","    else:\n","        print(f\"No 'eval/loss' tag found in {log_file}.\")\n","\n","    return train_losses, eval_losses\n","\n","# 加载并提取第一个事件文件的损失数据\n","log_file1 = './logs/events.out.tfevents.1719327193.e90606a6042e.9513.0'\n","train_losses1, eval_losses1 = load_and_extract_losses(log_file1)\n","\n","# 加载并提取第二个事件文件的损失数据\n","log_file2 = './logs/events.out.tfevents.1719329449.e90606a6042e.9513.1'\n","train_losses2, eval_losses2 = load_and_extract_losses(log_file2)\n","\n","# 打印一部分损失值，检查数据是否正确提取\n","print(f\"Train losses (File 1): {train_losses1[:10]}\")\n","print(f\"Eval losses (File 1): {eval_losses1[:10]}\")\n","print(f\"Train losses (File 2): {train_losses2[:10]}\")\n","print(f\"Eval losses (File 2): {eval_losses2[:10]}\")\n","\n","# 绘制损失曲线\n","plt.figure(figsize=(16, 8))\n","\n","# 绘制第一个文件的损失曲线\n","plt.subplot(1, 2, 1)\n","if train_losses1:\n","    plt.plot(train_losses1, label='Training Loss')\n","plt.plot(eval_losses1, label='Validation Loss')\n","plt.xlabel('Steps')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss (File 1)')\n","plt.legend()\n","plt.grid(True)\n","\n","# 绘制第二个文件的损失曲线\n","plt.subplot(1, 2, 2)\n","if train_losses2:\n","    plt.plot(train_losses2, label='Training Loss')\n","plt.plot(eval_losses2, label='Validation Loss')\n","plt.xlabel('Steps')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss (File 2)')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"9xspq1LmCXoG"},"execution_count":null,"outputs":[]}]}